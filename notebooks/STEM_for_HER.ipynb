{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vibe Check\n",
    "### Using Twitter’s API and Sentiment Analysis to Understand What’s the What on the Internet\n",
    "\n",
    "Today's session will cover:\n",
    "1.   Setting up Access to the Twitter API and Getting API Access Keys\n",
    "2.   Getting Data from Twitter using the Twitter API\n",
    "3.   Basic Data Operations and Data Cleaning\n",
    "4.   Sentiment Analysis With Python using NLTK\n",
    "\n",
    "<!--- TODO: Slides with: Intros - who we are, what does FN do overview, session goals/ what is an API + QR code with link to public google colab + session end slides - career guidance? (One of our learning objectives was \"What jobs or internships can you search for to use the skills covered in this workshop?\" -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhEkeNWy6Jp5"
   },
   "source": [
    "# Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APIs\n",
    "### What are APIs?\n",
    "\n",
    "An API is the most popular way to access data programmatically - API documentation will tell our clients what is available and how to “ask” our API for it.\n",
    "\n",
    "If you've ever seen tweets embedded on a webpage, those were pulled in via an API!\n",
    "\n",
    "First, we're going to set up some libraries, and our API authentication information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer <insert-token-here>\",\n",
    "    \"User-Agent\": \"stem-for-her-demo\"\n",
    "}\n",
    "\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Query\n",
    "\n",
    "<!--- Audience Participation here - ask for hashtags/ keyword search ideas - maybe pull up twitter trends on a screen? Live edit notebook to change search keywords-->\n",
    "\n",
    "-- Harry Styles, Elon Musk, other things that are trending, Taylor Swift tour?\n",
    "\n",
    "### Optional Fields\n",
    "tweet.fields lets us add specific fields -  here we add created_at\n",
    "\n",
    "### Query String\n",
    "\n",
    "-is:retweet *excludes* any retweets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "query_params = {'query': '#harrystyles -is:retweet',\n",
    "                'tweet.fields': 'created_at',\n",
    "                'expansions': 'author_id'}\n",
    "\n",
    "# TODO: Use stream tweets/ archive search to get more results than just 'recent'\n",
    "\n",
    "response = requests.get(search_url, headers=headers, params=query_params)\n",
    "print(response.status_code)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(response.status_code, response.text)\n",
    "\n",
    "json_response = response.json()\n",
    "print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "\n",
    "# TODO: Maybe add tweet counts and visualize a trend line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em6CB72b6aKV"
   },
   "source": [
    "# Getting Started with NLTK\n",
    "\n",
    "<!--- TODO: Add more here - what is NLP? Short explanation of word tokenization\n",
    "Ref: https://realpython.com/python-nltk-sentiment-analysis/#using-nltks-pre-trained-sentiment-analyzer\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%pip install nltk\n",
    "import nltk\n",
    "\n",
    "nltk.download([\"names\", \"stopwords\", \"averaged_perceptron_tagger\", \"vader_lexicon\",\"punkt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for item in json_response.get('data'):\n",
    "    words.extend(nltk.word_tokenize(item.get('text')))\n",
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "words_clean = [w for w in words if w.isalpha() and w not in unwanted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(words_clean)\n",
    "print(fd.most_common(5))\n",
    "print(fd.tabulate(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "tweets = [t['text'].replace(\"://\", \"//\") for t in json_response.get('data')]\n",
    "\n",
    "def is_positive(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "for t in tweets[:20]:\n",
    "    print(\">\", is_positive(t), t)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
