{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vibe Check\n",
    "## Using Twitter’s API and Sentiment Analysis to Understand What’s the What on the Internet\n",
    "\n",
    "Today's Agenda:\n",
    "1. Who We Are\n",
    "2. What are APIs?\n",
    "3. Using the Twitter API\n",
    "4. Basic Data Operations and Data Cleaning\n",
    "5. Sentiment Analysis With Python using NLTK\n",
    "\n",
    "<!--- TODO: Slides with: Intros - who we are, what does FN do overview, session goals/ what is an API + QR code with link to public google colab + session end slides - career guidance? (One of our learning objectives was \"What jobs or internships can you search for to use the skills covered in this workshop?\"\n",
    "\n",
    "Slides instructions: https://medium.com/@mjspeck/presenting-code-using-jupyter-notebook-slides-a8a3c3b59d67\n",
    " \n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # Who We Are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# FiscalNote\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Us\n",
    "\n",
    "## Annabelle Gary\n",
    "\n",
    "## Karnika Arora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# APIs\n",
    "### What are APIs?\n",
    "\n",
    "An API, or \"Application Programming Interface\", is the most popular way to access data programmatically - API documentation will tell our clients what is available and how to “ask” our API for it.\n",
    "\n",
    "If you've ever seen tweets embedded on a webpage, those were pulled in via an API!\n",
    "\n",
    "Most modern APIs return data in JSON format - the API we will be working with today does as well. JSON is a data format, just like an excel file is a format in which we store data - but JSON is more flexible and more lightweight, which makes it a great option for exchanging data over the internet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Today, we're going to access API data using Python. First, we'll set up some libraries and then our API authentication information.\n",
    "\n",
    "We have our \"bearer_token\" - this is like a secret password that belongs to only us so Twitter knows who exactly is asking it for data - stored in a file. We're going to read the data in after our imports, and set up our API request URL and the headers for the request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import requests # We use this library to make HTTP requests\n",
    "import json # To parse through the JSON data we get back from the API\n",
    "import urllib \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "with open(f\"../utils/bearer_token.txt\", \"r\") as token_file:\n",
    "    bearer_token = token_file.read()\n",
    "    \n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "}\n",
    "\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/recent?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You'll notice that we also set up what we need to make the actual request to the Twitter API, the headers and the request url:\n",
    "1. **Headers**: This information tells Twitter exactly who we are:\n",
    "    - Authorization: **`bearer_token`**: the secret password, this lets twitter know that we are allowed to access this data\n",
    "    \n",
    "<!--- Let's delete this: it is not required for the request:\n",
    "    - **`User-Agent`**: a name for what project we're working on.\n",
    "    - This information is important for Twitter to track so they can keep track of who is using their API and make sure that nobody is abusing the API. Pretty much every API will require you to identify yourself in some way before you can get data back. -->\n",
    "\n",
    "2. The URL we're going to request data from. In this case: `https://api.twitter.com/2/tweets/search/recent` - We figured this out by looking at twitter's API documentation. Most APIs have extensive documentation that will help you decide what request URL to use. Take a look at Twitter's API documentation here:\n",
    "\n",
    "[Twitter API Documentation](https://developer.twitter.com/en/docs/twitter-api/tweets/search/introduction)\n",
    "\n",
    " <!---\n",
    "    - **`api.twitter.com`**: tells Twitter we're trying to hit the API, as opposed to the main feed/user interface.\n",
    "    - **`2`**: shows that we're hitting Version 2.0 of the API. If we put `1` instead, we would hit the 1st version, which would both require slightly different request syntax, and would return data formatted differently.\n",
    "    - **`tweets`**: indicates which data type we want to request. We could also input `users`, `spaces`, or `lists` to get different datatypes back.\n",
    "    - **`search`**: says we want to search over tweets. We could also put `counts` to get the number of tweets, or we could look up tweets directly by their IDs. `search` allows us to give Twitter a query - a set of terms we want to include or exclude - and we'll get back tweets that match our query terms.\n",
    "    - **`recent`**: Twitter allows you to search either over only Tweets from the last week, or `all` Tweets, depending on your level of access. We'll stick to `recent`, because we're interested in what's happening on Twitter right now. \n",
    "    \n",
    " #karnika: I think this can be shorter. I propose completely nixing the bullets I commented out.\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building a Query\n",
    "\n",
    "See: https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n",
    "\n",
    "<!--- Audience Participation here - ask for hashtags/ keyword search ideas - maybe pull up twitter trends on a screen? Live edit notebook to change search keywords-->\n",
    "\n",
    "- Search queries are used all throughout the internet - google, twitter - pretty much any app you've used allows you to search. If you've ever used the google advanced search feature before, you'll notice that we use some similar syntax here to comstruct our search queries.\n",
    "\n",
    "- Our initial search will try to find tweets about Elon Musk - and then we'll take input from all of you and search for something you want to see!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "query_string = '#twitter ' # tweets #HarryStyles hashtag\n",
    "query_string += '\"elon musk\" ' # tweets that have \"watermelon sugar\" somewhere in their text\n",
    "query_string += '-is:retweet ' # eliminate retweets\n",
    "print(query_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> **Optional Fields**\n",
    ">\n",
    ">- tweet.fields lets us add specific fields -  here we add `created_at`\n",
    ">\n",
    ">**Query String**\n",
    ">\n",
    ">- is:retweet *excludes* any retweets\n",
    "\n",
    "See all the different operators types you can add to your search here: https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now, Let's turn our query string into a widget that we can easily edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "query_widget = widgets.Textarea(\n",
    "    value= query_string,\n",
    "    placeholder='Enter a search string',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")\n",
    "display(query_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Making the API Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GET vs POST requests\n",
    "\n",
    "When using APIs, there are multiple ways you can engage with them. The API Documentation will tell you what you're able to do, but one important thing to know about is what _type_ of requests you can make.\n",
    "\n",
    "`GET` requests are exactly what they sound like - you usually use them to _GET_ data back from the API. \n",
    "`POST` requests are a little more complicated, but generally they are used to _create_ data via the API. Any Twitter Bot you see is going to be using POST requests to create Tweets. See: https://twitter.com/MagicRealismBot\n",
    "\n",
    "Here, we'll make a `GET` request to get our response back from Twitter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "query_params = {'query': query_widget.value,\n",
    "                'tweet.fields': 'created_at,id,lang,source,text', # what data we want to return\n",
    "                'expansions': 'author_id'     # will include the profile ID of the author\n",
    "               }\n",
    "\n",
    "response = requests.get(url=search_url,params=query_params,\n",
    "                       headers=headers)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# HTTP Status Codes\n",
    "\n",
    "You've probably noticed that any website url will start with 'HTTP' - this stands for 'Hypertext Transfer Protocol', and this protocol decides how _servers_ and _browsers_ communicate. We don't have to get to deep into this, but it can be useful to understand what certain HTTP codes mean:\n",
    " - 200: This is a 'successful' response from the server\n",
    " - 400: The server is telling you that you made a bad request\n",
    " - 401: Unauthorized - the server is telling you that your authentication information is expired or incorrect\n",
    " - 500: Server Error - the server failed to respond\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = response.json()[\"data\"]\n",
    "print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualizing Our Data\n",
    " We'll use plotly and pandas to understand our twitter data a little bit better\n",
    " \n",
    " First, let's get _counts_ for our query and see what our data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "count_request = \"https://api.twitter.com/2/tweets/counts/recent\"\n",
    "count_query = {\n",
    "    \"query\": query_params['query'],\n",
    "    \"granularity\": \"day\"\n",
    "}\n",
    "tweet_counts = requests.get(count_request, params=count_query, headers=headers)\n",
    "print(tweet_counts.status_code)\n",
    "print(json.dumps(tweet_counts.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install plotly\n",
    "#%pip install pandas\n",
    "# create a requirements.txt file @Annabelle\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "\n",
    "tweet_count_df = pd.DataFrame(tweet_counts.json()[\"data\"]) \n",
    "tweet_count_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# When did dates get so complicated?\n",
    "\n",
    "#alwaysbegoogling\n",
    "\n",
    "This date format is pretty complex, and it includes a lot of information. This date is in the ISO 8601 representation. Before we simplify it a bit, let's see what each component means:\n",
    " - %Y - 2022 - The full four-digit date\n",
    " - %m - 11 - Two digit month (01 if it's 1)\n",
    " - %d - 29 - Two digit date\n",
    " - T - this marks the start of a timestamp\n",
    " - %H - 24h hour\n",
    " - %M - minute\n",
    " - %S - second \n",
    " - %f - milliseconds\n",
    " - Z - timezone offset\n",
    "> This time format can also be described as `%Y-%m-%dT%H:%M:%S.%fZ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "# Create a new column with just the simplified day\n",
    "for i, r in tweet_count_df.iterrows():\n",
    "    tweet_count_df.loc[i, 'day'] = dt.strptime(tweet_count_df.loc[i, 'start'], \"%Y-%m-%dT%H:%M:%S.%fZ\").date()\n",
    "    \n",
    "tweet_count_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizing Tweet Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Scatter(x=tweet_count_df['day'].astype(dtype=str), \n",
    "                        y=tweet_count_df['tweet_count'],\n",
    "                        marker_color='mediumvioletred', text=\"tweet_count\"))\n",
    "fig.update_layout({\"title\": 'Recent tweets',\n",
    "                   \"xaxis\": {\"title\":\"Days\"},\n",
    "                   \"yaxis\": {\"title\":\"Total tweets\"},\n",
    "                   \"showlegend\": False})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# This is a notes/ skip slide\n",
    "# just creates a function with the code from the first section so we can rerun it for the sentiment analysis portion\n",
    "# Create query widget before calling this function by running display(query_widget)\n",
    "# First obj returned is the count chart (display using fig.show(), second is the tweets obj)\n",
    "\n",
    "def get_tweets():\n",
    "    query_params = {'query': query_widget.value,\n",
    "                'tweet.fields': 'created_at,id,lang,source,text', # what data we want to return\n",
    "                'expansions': 'author_id'     # will include the profile ID of the author\n",
    "               }\n",
    "    response = requests.get(url=search_url,params=query_params,\n",
    "                       headers=headers)\n",
    "    count_request = \"https://api.twitter.com/2/tweets/counts/recent\"\n",
    "    count_query = {\n",
    "    \"query\": query_params['query'],\n",
    "    \"granularity\": \"day\"\n",
    "    }\n",
    "    tweet_counts = requests.get(count_request, params=count_query, headers=headers)\n",
    "    for i, r in tweet_count_df.iterrows():\n",
    "        tweet_count_df.loc[i, 'day'] = dt.strptime(tweet_count_df.loc[i, 'start'], \"%Y-%m-%dT%H:%M:%S.%fZ\").date()\n",
    "    fig = go.Figure(data=go.Scatter(x=tweet_count_df['day'].astype(dtype=str), \n",
    "                        y=tweet_count_df['tweet_count'],\n",
    "                        marker_color='mediumvioletred', text=\"tweet_count\"))\n",
    "    fig.update_layout({\"title\": 'Recent tweets',\n",
    "                   \"xaxis\": {\"title\":\"Days\"},\n",
    "                   \"yaxis\": {\"title\":\"Total tweets\"},\n",
    "                   \"showlegend\": False})\n",
    "    return fig, response.json()['data']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting Started with Sentiment Analysis\n",
    "\n",
    "<!--- TODO: Add more here - what is NLP? Short explanation of word tokenization\n",
    "Ref: https://realpython.com/python-nltk-sentiment-analysis/#using-nltks-pre-trained-sentiment-analyzer\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install nltk\n",
    "import nltk\n",
    "\n",
    "#nltk.download([\"names\", \"stopwords\", \"averaged_perceptron_tagger\", \"vader_lexicon\",\"punkt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "json_response = response.json()\n",
    "for item in json_response.get('data'):\n",
    "    words.extend(nltk.word_tokenize(item.get('text')))\n",
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "words_clean = [w for w in words if w.isalpha() and w not in unwanted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(words_clean)\n",
    "print(fd.most_common(10))\n",
    "print(fd.tabulate(5))\n",
    "# Remove the https? is that in stopwords?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is NLP, Machine Learning etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "tweets = [t['text'].replace(\"://\", \"//\") for t in json_response.get('data')]\n",
    "\n",
    "def is_positive(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia.polarity_scores(tweet)[\"compound\"] > 0, sia.polarity_scores(tweet)[\"compound\"]\n",
    "\n",
    "compound_sentiment = {'tweet': [], 'pos': [], 'comp_score': []}\n",
    "\n",
    "for t in tweets:\n",
    "    compound_sentiment['tweet'].append(t)\n",
    "    is_pos, score = is_positive(t)\n",
    "    compound_sentiment['pos'].append(is_pos)\n",
    "    compound_sentiment['comp_score'].append(score)\n",
    "\n",
    "compound_sentiment_df = pd.DataFrame(compound_sentiment)\n",
    "compound_sentiment_df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mean_sentiment = compound_sentiment_df.mean(numeric_only=True)['comp_score']\n",
    "\n",
    "tw_options = [(compound_sentiment_df.loc[i, 'tweet'], compound_sentiment_df.loc[i, 'comp_score']) for i, r in compound_sentiment_df.iterrows()]\n",
    "tw_options.append(('Average Score', mean_sentiment))\n",
    "tw_select = widgets.Dropdown(options=tw_options,\n",
    "                             value = mean_sentiment,\n",
    "                             description='Tweet:')\n",
    "caption = widgets.Label(value='initial pos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def create_gauge():\n",
    "    fig_gc = go.Figure(go.Indicator(\n",
    "        mode= \"gauge+number\",\n",
    "        value = tw_select.value,\n",
    "        gauge = {'axis': {'range': [-1, 1]},\n",
    "                 'bar': {'color':'darkslategray'},\n",
    "                 'steps': [{'range': [-1, 0], 'color': 'lightcoral'}, {'range': [0, 1], 'color': 'lightgreen'}]},\n",
    "        domain = {'x': [0,1], 'y': [0,1]},\n",
    "        title = \"Average sentiment\"))\n",
    "    # make space for explanation / annotation\n",
    "    fig_gc.update_layout(margin=dict(l=20, r=20, t=20, b=60),paper_bgcolor=\"white\")\n",
    "\n",
    "    # add annotation\n",
    "    fig_gc.add_annotation(dict(font=dict(color='darkslategray',size=15),\n",
    "                               x=0,\n",
    "                               y=-0.12,\n",
    "                               showarrow=False,\n",
    "                               text=tw_select.label,\n",
    "                               textangle=0,\n",
    "                               xanchor='left',\n",
    "                               xref=\"paper\",\n",
    "                               yref=\"paper\"))\n",
    "    return fig_gc\n",
    "\n",
    "gauge_chart = create_gauge()\n",
    "\n",
    "def handle_change(change):\n",
    "    gauge_chart.update_traces(go.Indicator(\n",
    "        mode= \"gauge+number\",\n",
    "        value = tw_select.value,\n",
    "        gauge = {'axis': {'range': [-1, 1]},\n",
    "                 'bar': {'color':'darkslategray'},\n",
    "                 'steps': [{'range': [-1, 0], 'color': 'lightcoral'}, {'range': [0, 1], 'color': 'lightgreen'}]},\n",
    "        domain = {'x': [0,1], 'y': [0,1]},\n",
    "        title = \"Average sentiment\"))\n",
    "\n",
    "    gauge_chart.update_annotations(dict(font=dict(color='darkslategray',size=15),\n",
    "                               x=0,\n",
    "                               y=-0.12,\n",
    "                               showarrow=False,\n",
    "                               text=tw_select.label,\n",
    "                               textangle=0,\n",
    "                               xanchor='left',\n",
    "                               xref=\"paper\",\n",
    "                               yref=\"paper\"))\n",
    "    clear_output()\n",
    "    display(tw_select)\n",
    "    gauge_chart.show()\n",
    "\n",
    "tw_select.observe(handle_change)\n",
    "display(tw_select)\n",
    "gauge_chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Take Two!\n",
    "\n",
    "What do you want to analyze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "display(query_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "count_chart, json_response = get_tweets()\n",
    "count_chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# @Annabelle - create a function here to re-run the nltk stuff? recreate tw_select and then:\n",
    "display(tw_select)\n",
    "gauge_chart.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "rise": {
   "scroll": true,
   "theme": "serif"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
